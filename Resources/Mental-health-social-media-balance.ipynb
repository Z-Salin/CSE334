{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13395699,"sourceType":"datasetVersion","datasetId":8500602,"isSourceIdPinned":false}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:47.864338Z","iopub.execute_input":"2025-10-22T11:19:47.865018Z","iopub.status.idle":"2025-10-22T11:19:47.871452Z","shell.execute_reply.started":"2025-10-22T11:19:47.864988Z","shell.execute_reply":"2025-10-22T11:19:47.870494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\nfrom kagglehub import KaggleDatasetAdapter\n\n# Set the correct file path, such as \"mental-health.csv\"\nfile_path = \"Mental_Health_and_Social_Media_Balance_Dataset.csv\"  # Adjust this based on the actual file name in the dataset\n\n# Load the latest version\ndf = kagglehub.dataset_load(  # Use dataset_load() instead of load_dataset()\n  KaggleDatasetAdapter.PANDAS,\n  \"prince7489/mental-health-and-social-media-balance-dataset\",\n  file_path,\n)\n\n# Show the first 5 records\nprint(\"First 5 records: \\n\", df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:48.24073Z","iopub.execute_input":"2025-10-22T11:19:48.240996Z","iopub.status.idle":"2025-10-22T11:19:48.363961Z","shell.execute_reply.started":"2025-10-22T11:19:48.240978Z","shell.execute_reply":"2025-10-22T11:19:48.36315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:48.692636Z","iopub.execute_input":"2025-10-22T11:19:48.692925Z","iopub.status.idle":"2025-10-22T11:19:48.697362Z","shell.execute_reply.started":"2025-10-22T11:19:48.692903Z","shell.execute_reply":"2025-10-22T11:19:48.696593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf['Gender'] = label_encoder.fit_transform(df['Gender'])\ndf = pd.get_dummies(df,columns=['Social_Media_Platform'],drop_first=True)\n\nx = df.drop(columns=['User_ID','Happiness_Index(1-10)'])\ny = df['Happiness_Index(1-10)']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:51.157762Z","iopub.execute_input":"2025-10-22T11:19:51.15805Z","iopub.status.idle":"2025-10-22T11:19:51.169032Z","shell.execute_reply.started":"2025-10-22T11:19:51.158027Z","shell.execute_reply":"2025-10-22T11:19:51.168379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:51.628534Z","iopub.execute_input":"2025-10-22T11:19:51.628806Z","iopub.status.idle":"2025-10-22T11:19:51.639068Z","shell.execute_reply.started":"2025-10-22T11:19:51.628787Z","shell.execute_reply":"2025-10-22T11:19:51.637902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:53.515799Z","iopub.execute_input":"2025-10-22T11:19:53.516094Z","iopub.status.idle":"2025-10-22T11:19:53.535473Z","shell.execute_reply.started":"2025-10-22T11:19:53.516071Z","shell.execute_reply":"2025-10-22T11:19:53.534479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:55.465576Z","iopub.execute_input":"2025-10-22T11:19:55.465887Z","iopub.status.idle":"2025-10-22T11:19:55.47269Z","shell.execute_reply.started":"2025-10-22T11:19:55.465863Z","shell.execute_reply":"2025-10-22T11:19:55.47179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('x_train,x_test,y_train,y_test :',len(x_train),len(x_test),len(y_train),len(y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:19:57.567073Z","iopub.execute_input":"2025-10-22T11:19:57.567761Z","iopub.status.idle":"2025-10-22T11:19:57.572835Z","shell.execute_reply.started":"2025-10-22T11:19:57.567721Z","shell.execute_reply":"2025-10-22T11:19:57.572005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(x_train_scaled,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:29:27.655867Z","iopub.execute_input":"2025-10-22T11:29:27.656879Z","iopub.status.idle":"2025-10-22T11:29:27.858626Z","shell.execute_reply.started":"2025-10-22T11:29:27.656836Z","shell.execute_reply":"2025-10-22T11:29:27.857658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = random_forest.predict(x_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:29:28.883692Z","iopub.execute_input":"2025-10-22T11:29:28.883994Z","iopub.status.idle":"2025-10-22T11:29:28.893759Z","shell.execute_reply.started":"2025-10-22T11:29:28.883971Z","shell.execute_reply":"2025-10-22T11:29:28.89283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error , r2_score\nmse = mean_squared_error(y_test,y_pred)\nprint(f'mse is : {mse}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:29:30.918526Z","iopub.execute_input":"2025-10-22T11:29:30.919101Z","iopub.status.idle":"2025-10-22T11:29:30.924704Z","shell.execute_reply.started":"2025-10-22T11:29:30.91908Z","shell.execute_reply":"2025-10-22T11:29:30.923919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Since happiness index is 1-10 \n# the mse range can be around 80+\n# a mse score of 0.8 means a roungh error of 0.9 point which is not that bad\n# tho it can be improved","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:29:32.817229Z","iopub.execute_input":"2025-10-22T11:29:32.818016Z","iopub.status.idle":"2025-10-22T11:29:32.821223Z","shell.execute_reply.started":"2025-10-22T11:29:32.817989Z","shell.execute_reply":"2025-10-22T11:29:32.820459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df['Gender'] = label_encoder.fit_transform(df['Gender'])\n# Works fine since \"Gender\" has few categories.\n# But LabelEncoder assigns arbitrary numbers (e.g., Male=1, Female=0, Other=2) → can accidentally introduce false “order” relationships.\n\n# Better:\n# Use one-hot encoding for Gender as well:\n\ndf = kagglehub.dataset_load(  # Use dataset_load() instead of load_dataset()\n  KaggleDatasetAdapter.PANDAS,\n  \"prince7489/mental-health-and-social-media-balance-dataset\",\n  file_path,\n)\n\nlabel_encoder = LabelEncoder()\ndf = pd.get_dummies(df,columns=['Social_Media_Platform','Gender'],drop_first=True)\n\nx = df.drop(columns=['User_ID','Happiness_Index(1-10)'])\ny = df['Happiness_Index(1-10)']\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n\n# Random Forest Does not care about scaling so no need to scale\n\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)\n\n\n# mse\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"MSE: {mse:.3f}\")\nprint(f\"RMSE: {rmse:.3f}\")\nprint(f\"R²: {r2:.3f}\")\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:34:19.603277Z","iopub.execute_input":"2025-10-22T11:34:19.60365Z","iopub.status.idle":"2025-10-22T11:34:19.92754Z","shell.execute_reply.started":"2025-10-22T11:34:19.603625Z","shell.execute_reply":"2025-10-22T11:34:19.926679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameter tuning (most important)\n# By default, RandomForestRegressor() uses small tree depth and few estimators — not optimal.\n# Use RandomizedSearchCV to find better settings:\n\nfrom sklearn.model_selection import RandomizedSearchCV\nrf = RandomForestRegressor(random_state=42)\n\nparam_dist = {\n    'n_estimators': [100, 200, 300, 500],\n    'max_depth': [None, 10, 20, 30, 50],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nsearch = RandomizedSearchCV(rf, param_distributions=param_dist,\n                             n_iter=25, cv=5, scoring='neg_mean_squared_error',\n                             n_jobs=-1, random_state=42)\nsearch.fit(x_train, y_train)\n\nbest_rf = search.best_estimator_\ny_pred = best_rf.predict(x_test)\n\n# mse\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"MSE: {mse:.3f}\")\nprint(f\"RMSE: {rmse:.3f}\")\nprint(f\"R²: {r2:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:35:32.340857Z","iopub.execute_input":"2025-10-22T11:35:32.341169Z","iopub.status.idle":"2025-10-22T11:35:52.996971Z","shell.execute_reply.started":"2025-10-22T11:35:32.341145Z","shell.execute_reply":"2025-10-22T11:35:52.996105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## These parameters actually increased the error , so we will stick to the traditional RandomForest \n## without any hyperparameter tuning\n\n## Learnt something new\n## What are the parameters used here \n# n_estimators : Number of trees in the forest.\n# max_depth : Maximum depth (levels) of each decision tree ; Controls how “deep” a tree can go before stopping.\n# min_samples_split : Minimum number of samples needed to split a node.\n# min_samples_leaf : Minimum number of samples required in a leaf (final node).\n\n# max_features :How many features to consider when looking for the best split \n # -->Controls the randomness between trees.\n # --> Fewer features = more diversity among trees → better generalization.\n # --> Common options:\n # --> 'sqrt' → use √(total features) per split (default for regression)\n # --> 'log2' → use log₂(total features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:38:41.245111Z","iopub.execute_input":"2025-10-22T11:38:41.24576Z","iopub.status.idle":"2025-10-22T11:38:41.249079Z","shell.execute_reply.started":"2025-10-22T11:38:41.245736Z","shell.execute_reply":"2025-10-22T11:38:41.248245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameter\t  :    Meaning\n# param_distributions\t:    The dictionary of parameters to test\n# n_iter\t:    How many random combinations to try (e.g., 25 random mixes of the above values)\n# cv\t:   Number of folds for cross-validation (e.g., 5 = splits data into 5 parts to test stability)\n# scoring='neg_mean_squared_error'\t:   Metric to optimize (lower MSE = better)\n# n_jobs=-1\t:     Uses all CPU cores for faster search\n# random_state=42\t:  Makes search reproducible","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T11:43:32.723789Z","iopub.execute_input":"2025-10-22T11:43:32.724088Z","iopub.status.idle":"2025-10-22T11:43:32.728405Z","shell.execute_reply.started":"2025-10-22T11:43:32.724068Z","shell.execute_reply":"2025-10-22T11:43:32.727584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}